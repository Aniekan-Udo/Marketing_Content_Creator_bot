{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9353719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/helpers.py\n",
    "import os\n",
    "import threading\n",
    "from functools import wraps\n",
    "from typing import Callable\n",
    "import structlog\n",
    "from structlog import get_logger\n",
    "from structlog.stdlib import LoggerFactory\n",
    "from structlog.dev import ConsoleRenderer\n",
    "from structlog.processors import TimeStamper, StackInfoRenderer, format_exc_info, add_log_level\n",
    "from structlog.processors import JSONRenderer\n",
    "\n",
    "from tenacity import retry, stop_after_delay, wait_exponential\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from cashews import cache\n",
    "from crewai.tools import BaseTool  \n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import (\n",
    "    Settings, \n",
    "    Document, \n",
    "    ServiceContext, \n",
    "    SimpleDirectoryReader, \n",
    "    StorageContext, \n",
    "    VectorStoreIndex,\n",
    "    load_index_from_storage \n",
    ")\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser, SimpleNodeParser\n",
    "\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "import threading\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "\n",
    "\n",
    "\n",
    "# Configure structlog once\n",
    "structlog.configure(\n",
    "    processors=[\n",
    "        add_log_level,\n",
    "        TimeStamper(fmt=\"iso\"),\n",
    "        StackInfoRenderer(),\n",
    "        format_exc_info,\n",
    "        JSONRenderer() if \"JSON\" in os.getenv(\"LOG_FORMAT\", \"console\") else ConsoleRenderer()\n",
    "    ],\n",
    "    logger_factory=LoggerFactory(),\n",
    "    wrapper_class=structlog.stdlib.BoundLogger,\n",
    "    cache_logger_on_first_use=True,\n",
    ")\n",
    "\n",
    "logger = get_logger(\"Marketing content creation bot\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e140d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm/groq_client.py\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from threading import Lock\n",
    "from typing import Dict\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "# Correct - module level (your original)\n",
    "_init_locks: Dict[str, Lock] = {}\n",
    "_locks_lock = Lock()\n",
    "\n",
    "def get_init_lock(business_id):\n",
    "    with _locks_lock:\n",
    "        if business_id not in _init_locks:\n",
    "            _init_locks[business_id] = Lock()\n",
    "        return _init_locks[business_id]\n",
    "\n",
    "\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_MODEL = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    logger.error(\"GROQ_API_KEY not found\") \n",
    "    raise\n",
    "\n",
    "def get_llm():\n",
    "    \"\"\"Get configured ChatGroq LLM instance.\"\"\"\n",
    "    return LLM(\n",
    "    model=\"groq/llama-3.3-70b-versatile\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0.6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a581a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "POSTGRES_URI = os.getenv(\"POSTGRES_URI\")\n",
    "\n",
    "if not POSTGRES_URI:\n",
    "    logger.error(\"POSTGRES_URI environment variable not set\")\n",
    "    raise ValueError(\"POSTGRES_URI environment variable not set\")\n",
    "\n",
    "\n",
    "\n",
    "class Marketing_Rag_System:\n",
    "    def __init__(self, data_path: str = \"./data/marketing\",business_id=None, \n",
    "                 content_type: str = \"default\"):\n",
    "        self._embed_model_cache=None\n",
    "        self._setup_lock= threading.Lock()\n",
    "        self.data_path= data_path\n",
    "        self.content_type=content_type\n",
    "        self.table_name = f\"rag_data_{business_id or 'default'}\"\n",
    "        self.business_id=business_id\n",
    "\n",
    "        get_init_lock(business_id)\n",
    "    \n",
    "    @retry(stop=stop_after_attempt(2))\n",
    "    def initialize_embedding_model(self):\n",
    "        if self._embed_model_cache is not None:\n",
    "            return self._embed_model_cache\n",
    "        with self._setup_lock:\n",
    "            if self._embed_model_cache is not None:\n",
    "                return self._embed_model_cache\n",
    "            \n",
    "            logger.info(\"Setting up embedding model...\")\n",
    "            \n",
    "            self.embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "            self._embed_model_cache = self.embed_model\n",
    "            logger.info(\"embedding model ready!\")\n",
    "            return self.embed_model\n",
    "\n",
    "\n",
    "    @cache(ttl=\"24h\", key=\"marketing_index:{self.table_name}\")\n",
    "    @retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_exponential(multiplier=1, min=2, max=10))\n",
    "    def build_marketing_index(self):\n",
    "\n",
    "        if not self.business_id:\n",
    "            logger.warn(\"Business ID not given\")\n",
    "\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        lock=get_init_lock(self.business_id)\n",
    "        with lock:\n",
    "        \n",
    "            if self.content_type == \"blog_article\":\n",
    "                parser = SemanticSplitterNodeParser.from_defaults(buffer_size=1, breakpoint_percentile_threshold=95)\n",
    "            elif self.content_type in [\"social_post\", \"ad_copy\", \"email_subject\"]:\n",
    "                parser = SimpleNodeParser.from_defaults(chunk_size=256, chunk_overlap=50)\n",
    "            else:\n",
    "                parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=100)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                vector_store = PGVectorStore.from_params(\n",
    "                    connection_string=POSTGRES_URI, \n",
    "                    table_name=self.table_name, \n",
    "                    embed_dim=384,\n",
    "                    hybrid_search=True, \n",
    "                    perform_setup=True,\n",
    "                    hnsw_kwargs={\n",
    "                        \"hnsw_m\": 16,                      # Links per node (higher = better recall)\n",
    "                        \"hnsw_ef_construction\": 64,        # Build-time search depth\n",
    "                        \"hnsw_ef_search\": 40,              # Query-time search depth\n",
    "                        \"hnsw_dist_method\": \"vector_cosine_ops\"  # Distance metric\n",
    "                    }\n",
    "                        )\n",
    "                \n",
    "                Settings.embed_model= self.initialize_embedding_model()\n",
    "                Settings.llm = None \n",
    "                Settings.node_parser = parser\n",
    "                storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "                \n",
    "                # Try to connect to existing index\n",
    "                try:\n",
    "                    index = VectorStoreIndex.from_vector_store(\n",
    "                        vector_store=vector_store,\n",
    "                        embed_model=Settings.embed_model\n",
    "                    )\n",
    "                    logger.info(f\"Connected to existing index: {self.table_name}\")\n",
    "                except Exception as e:\n",
    "                    # Build new if doesn't exist\n",
    "                    logger.info(f\"Building new index: {self.table_name}\")\n",
    "                    documents = SimpleDirectoryReader(self.data_path).load_data()\n",
    "                    if not documents:\n",
    "                        raise ValueError(f\"No documents found in {self.data_path}\")\n",
    "                    \n",
    "                    index = VectorStoreIndex.from_documents(\n",
    "                        documents,\n",
    "                        storage_context=storage_context,\n",
    "                        show_progress=True\n",
    "                    )\n",
    "                            \n",
    "                logger.info(f\"Index ready: {self.table_name} ({self.content_type})\")\n",
    "                return index\n",
    "            except Exception as e:\n",
    "                logger.error(\"Index build failed\", error=str(e), error_type=type(e).__name__)\n",
    "                raise\n",
    "\n",
    "\n",
    "VALID_CONTENT_TYPES = {\"blog\", \"social\", \"ad\"}\n",
    "\n",
    "class BrandVoiceKnowledgeBase:\n",
    "    \"\"\"Manages brand voice knowledge bases for different content types\"\"\"\n",
    "    \n",
    "    def __init__(self, postgres_uri: Optional[str] = None, llm=None,business_id=\"default\"):\n",
    "        self.postgres_uri = postgres_uri or POSTGRES_URI\n",
    "        self.llm = get_llm()\n",
    "        self.business_id=business_id\n",
    "        \n",
    "        # Lazy-loaded knowledge bases\n",
    "        self._blog_kb = None\n",
    "        self._social_kb = None\n",
    "        self._ad_kb = None\n",
    "        \n",
    "        # Track which KBs failed to load\n",
    "        self._load_errors = {}\n",
    "    \n",
    "    @property\n",
    "    def blog_kb(self):\n",
    "        \"\"\"Lazy-load blog knowledge base\"\"\"\n",
    "        if self._blog_kb is None and \"blog\" not in self._load_errors:\n",
    "            try:\n",
    "                rag_system = Marketing_Rag_System(\n",
    "                data_path=\"./brand_blogs\",\n",
    "                content_type=\"blog_article\",\n",
    "                table_name=f\"brand_blog_posts_{self.business_id}\",\n",
    "                business_id=self.business_id\n",
    "            )\n",
    "                self._blog_kb = rag_system.build_marketing_index()\n",
    "            except Exception as e:\n",
    "                logger.info(f\"Failed to load blog KB: {e}\")\n",
    "                self._load_errors[\"blog\"] = str(e)\n",
    "                raise\n",
    "        return self._blog_kb\n",
    "    \n",
    "    @property\n",
    "    def social_kb(self):\n",
    "        \"\"\"Lazy-load social knowledge base\"\"\"\n",
    "        if self._social_kb is None and \"social\" not in self._load_errors:\n",
    "            try:\n",
    "                rag_system= Marketing_Rag_System(data_path= \"./brand_social\", \n",
    "                                                 content_type=\"social_post\",\n",
    "                                                table_name=f\"brand_social_posts_{self.business_id}\",\n",
    "                                                business_id=self.business_id)\n",
    "\n",
    "                self._social_kb = rag_system.build_marketing_index()\n",
    "            except Exception as e:\n",
    "                logger.info(f\"Failed to load social KB: {e}\")\n",
    "                self._load_errors[\"social\"] = str(e)\n",
    "                raise\n",
    "        return self._social_kb\n",
    "    \n",
    "    @property\n",
    "    def ad_kb(self):\n",
    "        \"\"\"Lazy-load ad knowledge base\"\"\"\n",
    "        if self._ad_kb is None and \"ad\" not in self._load_errors:\n",
    "            try:\n",
    "                rag_system= Marketing_Rag_System(data_path= \"./brand_ads\", \n",
    "                                                 content_type=\"ad_copy\",\n",
    "                                                table_name=f\"brand_ad_copy_{self.business_id}\",\n",
    "                                                business_id=self.business_id)\n",
    "                \n",
    "                self._ad_kb = rag_system.build_marketing_index()\n",
    "            except Exception as e:\n",
    "                logger.info(f\"Failed to load ad KB: {e}\")\n",
    "                self._load_errors[\"ad\"] = str(e)\n",
    "                raise\n",
    "        return self._ad_kb\n",
    "    \n",
    "    def _get_llm(self):\n",
    "        \"\"\"Get LLM, creating if needed\"\"\"\n",
    "        if self.llm is None:\n",
    "            self.llm = get_llm()\n",
    "        return self.llm\n",
    "    \n",
    "    def get_style_guide(self, content_type: str, business_id):\n",
    "        \"\"\"Get query engine for specified content type\"\"\"\n",
    "        if content_type not in VALID_CONTENT_TYPES:\n",
    "            raise ValueError(\n",
    "                f\"Invalid content_type '{content_type}'. \"\n",
    "                f\"Must be one of: {VALID_CONTENT_TYPES}\"\n",
    "            )\n",
    "        \n",
    "        # Check if this KB failed to load\n",
    "        if content_type in self._load_errors:\n",
    "            raise ValueError(\n",
    "                f\"Knowledge base for '{content_type}' failed to load: \"\n",
    "                f\"{self._load_errors[content_type]}\"\n",
    "            )\n",
    "        self.business_id=business_id\n",
    "        get_init_lock(business_id)\n",
    "        llm = self._get_llm()\n",
    "        \n",
    "        kb_config = {\n",
    "            \"blog\": (self.blog_kb, 3),\n",
    "            \"social\": (self.social_kb, 2),\n",
    "            \"ad\": (self.ad_kb, 2)\n",
    "        }\n",
    "        \n",
    "        kb, top_k = kb_config[content_type]\n",
    "        return kb.as_query_engine(\n",
    "            similarity_top_k=top_k,\n",
    "            response_mode=\"compact\",\n",
    "            llm=llm\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "class KBQueryTool(BaseTool):\n",
    "    name: str = \"kb_query\"\n",
    "    description: str = \"...\"\n",
    "    kb: BrandVoiceKnowledgeBase  \n",
    "    \n",
    "    def __init__(self, kb: BrandVoiceKnowledgeBase, business_id):\n",
    "        super().__init__()\n",
    "        self.kb = kb\n",
    "        self.business_id=business_id\n",
    "    \n",
    "    def _run(self, **kwargs: Any) -> str:\n",
    "        \"\"\"CrewAI passes args as kwargs dict.\"\"\"\n",
    "        content_type = kwargs.get(\"content_type\")\n",
    "        query = kwargs.get(\"query\")\n",
    "        \n",
    "        # Validate\n",
    "        if not content_type or not query:\n",
    "            return \"Error: Missing content_type or query\"\n",
    "        \n",
    "        if content_type not in VALID_CONTENT_TYPES:\n",
    "            return f\"Error: content_type must be one of {VALID_CONTENT_TYPES}\"\n",
    "        \n",
    "        try:\n",
    "            style_guide = self.kb.get_style_guide(content_type, self.business_id)\n",
    "            response = style_guide.query(query)\n",
    "            return str(response)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"KB query failed: {e}\")\n",
    "            return self._get_fallback_response(content_type)\n",
    "    \n",
    "    def _get_fallback_response(self, content_type: str) -> str:\n",
    "        \"\"\"Provide fallback guidelines when KB unavailable\"\"\"\n",
    "        fallbacks = {\n",
    "            \"blog\": \"\"\"BRAND FALLBACK (KB unavailable):\n",
    "- Formal tone, 18±2 word sentences\n",
    "- Precise vocabulary (avoid 'leverage' → use 'use')\n",
    "- Authoritative but approachable\n",
    "- Structure: Problem → Solution → CTA\"\"\",\n",
    "            \n",
    "            \"social\": \"\"\"BRAND FALLBACK (KB unavailable):\n",
    "- Conversational, 10-15 words per post\n",
    "- Emoji-friendly, engaging CTAs\n",
    "- Brand hashtags, trending topics\n",
    "- Authentic voice\"\"\",\n",
    "            \n",
    "            \"ad\": \"\"\"BRAND FALLBACK (KB unavailable):\n",
    "- Clear value prop, 5-10 words\n",
    "- Action-oriented, benefit-focused\n",
    "- Urgency without pressure\n",
    "- Strong CTAs\"\"\"\n",
    "        }\n",
    "        return fallbacks.get(content_type, fallbacks[\"blog\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f704a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "load_dotenv()\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "if not tavily_api_key:\n",
    "    logger.info(\"tavily_api_key not found\")\n",
    "\n",
    "\n",
    "class TavilySearchTool(BaseTool):\n",
    "    name: str = \"tavily_search\"\n",
    "    description: str = \"Search the web using Tavily API for research queries\"\n",
    "    \n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Execute Tavily search.\"\"\"\n",
    "        client = TavilyClient(api_key=tavily_api_key)\n",
    "        result = client.search(query)\n",
    "        return str(result)\n",
    "\n",
    "tavily_search = TavilySearchTool()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f00988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4362887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "LEARNING_FILE = Path(\"data/reviewer_learning.json\")\n",
    "LEARNING_FILE.parent.mkdir(exist_ok=True)\n",
    "\n",
    "# PROPER CrewAI BaseTool IMPLEMENTATION\n",
    "class ReviewerAccuracyTool(BaseTool):\n",
    "    name: str = \"update_reviewer_accuracy\"\n",
    "    description: str = \"Update reviewer learning from human feedback. Tracks accuracy over time.\"\n",
    "    \n",
    "    def _run(self, kb_score: float, confidence: float, human_approved: bool) -> str:\n",
    "        \"\"\"Persistently track reviewer accuracy after human feedback.\"\"\"\n",
    "        if LEARNING_FILE.exists():\n",
    "            history = json.loads(LEARNING_FILE.read_text())\n",
    "        else:\n",
    "            history = {\"total\": 0, \"correct\": 0, \"reviews\": []}\n",
    "        \n",
    "        agent_auto_approved = (kb_score >= 8.5)\n",
    "        was_correct = (agent_auto_approved == human_approved)\n",
    "        \n",
    "        history[\"total\"] += 1\n",
    "        history[\"correct\"] += 1 if was_correct else 0\n",
    "        history[\"reviews\"].append({\n",
    "            \"kb_score\": kb_score,\n",
    "            \"confidence\": confidence,\n",
    "            \"human_approved\": human_approved,\n",
    "            \"agent_correct\": was_correct,\n",
    "            \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        })\n",
    "        \n",
    "        history[\"reviews\"] = history[\"reviews\"][-200:]\n",
    "        LEARNING_FILE.write_text(json.dumps(history, indent=2))\n",
    "        \n",
    "        accuracy = history[\"correct\"] / history[\"total\"] if history[\"total\"] > 0 else 1.0\n",
    "        return f\"{accuracy:.1%}\"\n",
    "\n",
    "update_reviewer_accuracy = ReviewerAccuracyTool()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc09209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployer.py\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "from crewai import Crew, Process\n",
    "\n",
    "\n",
    "\n",
    "class ContentCrewFactory:\n",
    "    def __init__(self, kb:BrandVoiceKnowledgeBase,\n",
    "                 tavily_search:TavilySearchTool,\n",
    "                 update_reviewer_accuracy:ReviewerAccuracyTool,\n",
    "                 business_id ):\n",
    "        self.kb=kb\n",
    "        self.tavily_search=tavily_search\n",
    "        self.update_reviewer_accuracy=update_reviewer_accuracy\n",
    "        self.business_id=business_id\n",
    "        \n",
    "    def create_crew(self)-> Crew:\n",
    "        kb_tool = KBQueryTool(kb=self.kb, business_id=self.business_id)\n",
    "        self.llm = get_llm() \n",
    "\n",
    "        researcher_agent = Agent(\n",
    "            role=\"Research Analyst\",\n",
    "            goal=\"Find and summarize specific topics\",\n",
    "            backstory=\"Experienced researcher with attention to detail.\",\n",
    "            tools=[self.tavily_search],\n",
    "            llm=get_llm(), \n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        research_task = Task(\n",
    "            description=\"\"\"\n",
    "                Research {topic} for {format}.\n",
    "                Consider current trends in 2026.\n",
    "            \"\"\",\n",
    "            expected_output=\"10 bullet points of relevant information.\",\n",
    "            agent=researcher_agent,\n",
    "        )\n",
    "        \n",
    "        writer_agent = Agent(\n",
    "            role=\"Brand-Aligned Content Writer\",\n",
    "            goal=\"Write matching {brand_style} from KB\",\n",
    "            backstory=\"\"\"\n",
    "            Expert at replicating brand voice. ALWAYS query KB first.\n",
    "            Extract: tone, style, structure, phrasing from examples.\n",
    "            \"\"\",\n",
    "            tools=[kb_tool],\n",
    "            llm=get_llm(),\n",
    "            verbose=True,\n",
    "            memory=True,\n",
    "        )\n",
    "\n",
    "        writer_task = Task(\n",
    "            description=\"\"\"\n",
    "            Write {topic} in {format}:\n",
    "            1. Query KB for 3-5 relevant examples\n",
    "            2. Analyze brand patterns\n",
    "            3. Match exactly\n",
    "            4. End with brand alignment confidence\n",
    "            \"\"\",\n",
    "            agent=writer_agent,\n",
    "            context=[research_task],\n",
    "            expected_output=\"A piece of content that matches the brand style with confidence score\"\n",
    "        )\n",
    "\n",
    "        reviewer_agent = Agent(\n",
    "                role=\"Brand Style Enforcer\",\n",
    "                goal=\"Enforce brand alignment via KB + self-calibration\",\n",
    "                backstory=\"\"\"\n",
    "                Protocol:\n",
    "                1. Query KB multiple times (tone/structure/vocab)\n",
    "                2. Compute composite score\n",
    "                3. HITL only if uncertain (score 5-7, conf <0.8)\n",
    "                4. Learn from human feedback\n",
    "                \"\"\",\n",
    "                tools=[kb_tool, self.update_reviewer_accuracy],\n",
    "                memory=True,\n",
    "                verbose=True,\n",
    "                llm=get_llm()\n",
    "            )\n",
    "        \n",
    "        reviewer_task = Task(\n",
    "                description=\"\"\"\n",
    "                Review writer output:\n",
    "                1. KB deep dive (tone, structure, vocab)\n",
    "                2. Compute kb_score, confidence\n",
    "                3. Decide HITL or auto-approve (>=8.5)\n",
    "                4. Learn post-human input\n",
    "                \"\"\",\n",
    "                agent=reviewer_agent,\n",
    "                context=[writer_task],\n",
    "                human_input=True,\n",
    "                expected_output=\"JSON matching ReviewOutput schema\",\n",
    "            )\n",
    "\n",
    "        return Crew(\n",
    "            agents=[researcher_agent, writer_agent, reviewer_agent],\n",
    "            tasks=[research_task, writer_task, reviewer_task],\n",
    "            process=Process.sequential,\n",
    "            verbose=True,\n",
    "            )\n",
    "\n",
    "\n",
    "# deployer.py - Entry point (CLI/API)\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--topic\", default=\"AI Agents\")\n",
    "    parser.add_argument(\"--format\", default=\"LinkedIn Post\")\n",
    "    parser.add_argument(\"--voice\", default=\"formal\")  # ← ADD THIS LINE\n",
    "    parser.add_argument(\"--business_id\", default=\"default\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Initialize per-request dependencies\n",
    "    \n",
    "    kb = BrandVoiceKnowledgeBase(business_id=\"default\")\n",
    "    factory = ContentCrewFactory(\n",
    "        kb=kb,\n",
    "        tavily_search=tavily_search,\n",
    "        update_reviewer_accuracy=update_reviewer_accuracy,\n",
    "        business_id=\"default\"\n",
    "        \n",
    "    )\n",
    "    crew = factory.create_crew()\n",
    "    \n",
    "    # Execute\n",
    "    result = crew.kickoff(inputs={\n",
    "        \"topic\": args.topic,\n",
    "        \"format\": args.format,\n",
    "    })\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
